# ðŸ§ª **541â€“560: Testing in Go**

### 541. How do you write table-driven tests in Go?
"It's the idiomatic standard.
I define a struct array: `tests := []struct { input string; want int }`.
Then I loop: `for _, tt := range tests { t.Run(tt.name, ...) }`.
This makes it trivial to add 20 edge cases (empty strings, huge numbers) without copy-pasting logic. The `t.Run` creates subtests, allowing me to run specific cases via `go test -run=TestMyFunc/Case1`."

#### Indepth
`t.Parallel()` is the superpower of Table-Driven tests. By adding `tt := tt; t.Run(..., func(t *testing.T) { t.Parallel(); ... })`, you can run 100 test cases across all available CPU cores. *Note*: The `tt := tt` capture is not needed in Go 1.22+, as loop variables are safe.

---

### 542. What is the difference between `t.Fatal` and `t.Errorf`?
"**`t.Error`**: Marks failure but **continues execution**. I use this when checking multiple independent fields (e.g., Status Code is wrong, but I also want to see if the Body is wrong).
**`t.Fatal`**: Marks failure and **stops immediately**. I use this when setup fails (DB didn't connect, or file not found) because proceeding would just cause a panic."

#### Indepth
Use `t.Helper()` in your utility functions (like `assertUserID`). This marks the helper function as "not the cause of the error" in the stack trace, so when the test fails, the log points to the line in `TestMyFunc` that called the helper, not the helper itself.

---

### 543. How do you use `go test -cover` to check coverage?
"`go test -coverprofile=c.out ./...`.
Then `go tool cover -html=c.out`.
This opens a visual HTML report. Green lines are covered, red are missed.
I aim for high coverage (80%) in business logic packages. I ignore boilerplate/generated code.
Crucially, I check **branch coverage** (did I test both the `if err != nil` and the `else` path?)."

#### Indepth
For critical packages, enable `atomic` mode: `go test -race -covermode=atomic`. The default coverage mode is not thread-safe and can panic if tests run in parallel. Atomic mode uses `sync/atomic` counters, which is slower but correct for concurrent code.

---

### 544. How do you mock a database in Go tests?
"Two approaches:
1.  **Interfaces**: I define a `Repository` interface. In tests, I inject a `MockRepository` (manual or generated by `vektra/mockery`).
2.  **Docker (TestContainers)**: I spin up a real ephemeral Postgres for the test.
I prefer Docker for integration tests because SQL mocking is brittleâ€”a mock returning success doesn't prove my SQL syntax is valid."

#### Indepth
If using `pgx` (Postgres driver), consider `pgxmock` which mimics the compiled binary protocol. But nothing beats `testcontainers-go`. It spins up a fresh Postgres container in 500ms, runs migrations, tests against real DB constraints, and kills the container. It's the gold standard for integration tests.

---

### 545. How do you unit test HTTP handlers?
"I use `net/http/httptest`.
`req := httptest.NewRequest("GET", "/users", nil)`.
`w := httptest.NewRecorder()`.
`myHandler(w, req)`.
`resp := w.Result()`.
This runs the handler directly in memory without opening a network port. Itâ€™s incredibly fast and lets me inspect headers, status codes, and JSON bodies easily."

#### Indepth
Test middleware too! Often bugs hide in the middleware chain (Auth, CORS) which `myHandler(w, req)` might skip if you test the handler function in isolation. Consistently test the "assembled" router (e.g., `router.ServeHTTP(w, req)`) to ensure the full request lifecycle works.

---

### 546. What is testable design and how does Go encourage it?
"Testable design means **Dependency Injection**.
Instead of `db := sql.Open(...)` inside my handler (hard to test), I pass the DB as a dependency to the handler struct.
`func NewHandler(db DBInterface) *Handler`.
Go's implicit interfaces make this pattern natural. I define the interface where I *use* it, allowing me to mock anything easily."

#### Indepth
Beware of "Interface Pollution". Don't define a big `UserStruct` interface with 20 methods. Define tiny interfaces where you *use* them: `type UserFetcher interface { Fetch(id int) User }`. This "Consumer-Defined Interface" pattern makes mocking trivial (just mock 1 method) and keeps dependencies loose.

---

### 547. How do you use interfaces to improve testability?
"I define consumer-driven interfaces.
If my service needs to send emails, I define:
`type EmailSender interface { Send(to, body string) error }`.
In production, I inject `SMTPSender`.
In tests, I inject `MockSender` that just records the call. This decouples my business logic from the slow, external SMTP server."

#### Indepth
Mocking variadic functions or functions with complex structs can be tedious. Generated mocks (Mockery/Gomock) are fine, but "Hand-written Mocks" are often clearer. `type MockSender struct { SendFunc func(...) error }`. This lets you swap behavior inline in the test: `m.SendFunc = func(...) { return error }`.

---

### 548. How do you write tests for concurrent code in Go?
"I use the **Race Detector** (`go test -race`).
And I use channels to synchronize.
`done := make(chan bool)`.
`go func() { doWork(); done <- true }`.
`<-done`.
For complex race conditions, I run the test in a loop `go test -count=100` to increase the chance of the scheduler triggering the specific interleaving that causes the bug."

#### Indepth
The `-race` detector adds ~10x CPU overhead and ~5-10x memory usage. Don't run it in production. But *always* run it in CI. It uses a "Happens-Before" vector clock algorithm to detect unsynchronized memory access with zero false positives.

---

### 549. What is the `httptest` package and how is it used?
"It provides utilities for HTTP testing.
**`ResponseRecorder`**: Records the response of a handler (status, body).
**`Server`**: Starts a real HTTP server on a random local port.
`ts := httptest.NewServer(http.HandlerFunc(...))`.
I use `ts.URL` as the API endpoint in my client tests. It simulates a real server environment."

#### Indepth
`httptest.NewServer` picks a random open port, preventing "Address already in use" errors during parallel tests. It also supports HTTP/2 (`NewUnstartedServer` + `EnableHTTP2`). Use it when testing your *HTTP Client* code (retries, timeouts) against a real (but local) network socket.

---

### 550. How do you mock time in tests?
"I never use `time.Now()` directly in logic.
I define a `Clock` interface: `Now() time.Time`.
In prod: `RealClock`.
In tests: `MockClock`.
`mockClock.Set(time.Date(2023, 1, 1...))`.
This allows me to verify logic like 'token expires in 1 hour' deterministically, without sleeping for an hour in the test."

#### Indepth
For strict time testing, use a library like `glock` or `clockwork`. They provide a `FakeClock` that lets you `Advance(1 * time.Hour)`. This triggers all waiting `time.After/Sleep` channels instantly, making "wait for 1 hour" tests run in microseconds.

---

### 551. How do you perform integration testing in Go?
"I separate them with build tags.
`//go:build integration`.
In the file: `func TestUserSignup_Integration(t *testing.T)`.
I run unit tests fast: `go test -short ./...`.
I run integration tests slow: `go test -tags=integration ./...`.
This keeps the developer feedback loop fast (milliseconds) while ensuring correctness in CI (seconds)."

#### Indepth
Create a `Makefile` or `Taskfile` to simplify this. `make test` runs unit tests. `make test-all` runs everything. Also, integration tests often require env vars (`POSTGRES_DSN`). Use `os.Getenv` in `TestMain` to skip the test (or `t.Skip()`) if the environment isn't set up (e.g., on a laptop without Docker).

---

### 552. How do you use `testify/mock` for mocking dependencies?
"I use `mockery` to generate the code.
`mockery --name=Database`.
In tests:
`mockDB := new(mocks.Database)`.
`mockDB.On("GetUser", 123).Return(user, nil)`.
It allows strict expectations: 'GetUser must be called exactly once with arg 123'. If the code calls it twice vs zero times, the test fails."

#### Indepth
Don't verify *everything*. `mock.Anything` is your friend. Over-specifying mocks (`On("Log", "User 123 logged in at 12:00").Return(nil)`) makes tests brittle; they break if you change a timestamp format. Verify the *side effects that matter* (DB writes), not the noise (logs).

---

### 553. How do you run subtests and benchmarks?
"**Subtests**: `t.Run("case 1", func(t *testing.T) { ... })`. Allows grouping and running specific cases.
**Benchmarks**: `func BenchmarkX(b *testing.B)`.
`b.Run("small payload", ...)`
`b.Run("large payload", ...)`
This gives me a comparative performance report for different inputs in a single run."

#### Indepth
Benchmarks are not just for speed; they track allocations! `b.ReportAllocs()`. If a commit changes `0 allocs/op` to `1 allocs/op` in a hot path, that's a regression. CI tools like `gobenchdata` can graph these trends over time to catch performance degradation.

---

### 554. How do you test panic recovery?
"I use a `defer-recover` block.
`defer func() { if r := recover(); r == nil { t.Errorf("did not panic") } }()`
`triggerPanic()`.
Or use `assert.Panics(t, func(){ ... })` from testify.
Testing panics is vital for library code where I want to ensure bad inputs (like index out of bounds) don't crash the user's application."

#### Indepth
Recover returns `any`, because you can `panic("string")` or `panic(error)`. Always type assert the result: `err, ok := r.(error)`. Also, remember `recover()` only works if called directly inside a `defer` function. It does nothing if called in a regular function nested inside the defer.

---

### 555. How do you generate test data using faker or random data?
"I use libraries like `gofakeit` or `go-faker`.
`email := gofakeit.Email()`.
`name := gofakeit.Name()`.
This prevents 'testing bias' where I always test with 'John Doe'.
Random data often reveals edge cases (e.g., names with apostrophes or emails with `+` signs) that my regex validation missed."

#### Indepth
Property-Based Testing (`gopter` or `rapid`). Instead of picking 1 random email, you define a property: "For *any* valid string s, `Reverse(Reverse(s)) == s`". The library generates thousands of edge cases (empty, emojis, control chars) to try and falsify your property.

---

### 556. What is golden file testing and when is it useful?
"For complex output (huge JSON/HTML).
I don't assert field-by-field.
I assert: `got == readFile("testdata/expected.json")`.
If I change logic intentionally, I run `go test -update`.
This overwrites the golden file with the new output. It makes maintaining tests for large data structures trivial."

#### Indepth
Git attributes! Mark golden files as generated or binary in `.gitattributes` so they don't clutter PR diffs. `testdata/*.golden -diff`. Or ensure `diff` uses a custom driver. This keeps your code review focused on Logic changes, not 500 lines of JSON output changes.

---

### 557. How do you automate test workflows with `go generate`?
"I put `//go:generate mockery --all` in `main.go`.
Running `go generate ./...` rebuilds all my mocks.
I also use it to generate Wire dependency injection code (`google/wire`).
It ensures that my generated test helpers are always up-to-date with my interfaces."

#### Indepth
The tool directive: Add `//go:generate go run github.com/vektra/mockery/v2@latest` to control the version of the tool used. Better yet, create a `tools.go` file with blank imports to track tool dependencies in `go.mod`, ensuring the whole team uses the exact same version of the code generator.

---

### 558. How do you test CLI apps built with Cobra?
"I redirect `os.Stdout` and `os.Stdin`.
Better yet, I inject `io.Reader` and `io.Writer` into my `RootCmd.RunE`.
In tests:
`buf := new(bytes.Buffer)`
`cmd.SetOut(buf)`
`cmd.Execute()`
Then I assert `buf.String()` contains the expected output. This tests the CLI wiring without spawning a child process."

#### Indepth
Testing Flags: Use `SetArgs([]string{"--flag", "value"})`. Don't rely on `os.Args`. Testing interactive prompts is harder; you might need a pseudo-terminal library or restructure your code to read from a generic `Scanner` interface that you can mock with a string buffer.

---

### 559. What is fuzz testing and how do you do it in Go?
"Go 1.18+ has native fuzzing.
`func FuzzParse(f *testing.F)`.
I seed it with valid inputs: `f.Add("valid")`.
Then `f.Fuzz(func(t *testing.T, data []byte) { ... })`.
The runtime generates random mutations of `data`.
I assert that my function **does not crash** (panic) and holds invariant properties (e.g., `Decode(Encode(data)) == data`)."

#### Indepth
Seed Corpus is vital. Go fuzzing saves "interesting" inputs that cause new code paths to `testdata/fuzz`. check these into Git! They become your regression suite. If a fuzz input found a bug, that input *must* be run forever to ensure the bug stays dead.

---

### 560. How do you organize test files and test suites?
"I place unit tests next to the code: `user.go` and `user_test.go`.
I use `package mypkg` for white-box testing (access private internals).
I use `package mypkg_test` for black-box testing (public API only).
For integration tests, I put them in a separate `tests/` folder if they span multiple packages, often using a `TestMain` for global setup/teardown."

#### Indepth
`internal` packages: You can't import `internal` from an external test package (`package foo_test`). If you need to test deep internals of `internal/auth` from `cmd/api`, you can't. Move the test *into* the package (`package foo`), or expose a "Test Hook" (export a variable only in `export_test.go`) to give the test access.
